---
description: A guide on how to handle loading various media resources.
---

import hlsManifestImage from '~/images/hls-manifest.png';

## Sizing

By default, the browser will use the [intrinsic size][intrinsic-size] of the loaded media to
set the dimensions of the provider. As media loads over the network, the element will jump
from the default size to the intrinsic media size, triggering a layout shift which is a [poor
user experience indicator][cumulative-layout-shift] for both your users and search
engines (i.e., Google).

**Aspect Ratio**

To avoid a layout shift, we recommend setting the aspect ratio like so:

::code[./layout-shift]{ext=true}

Ideally the ratio set should match the ratio of the media content itself (i.e., intrinsic aspect ratio)
otherwise you'll end up with a letterbox template (empty black bars on the left/right of the media).

**Specify Dimensions**

If you'd like to be more specific for any reason, you can specify the `width` and `height` of the
player simply using CSS like so:

::code[./dimensions]

[intrinsic-size]: https://developer.mozilla.org/en-US/docs/Glossary/Intrinsic_Size
[cumulative-layout-shift]: https://web.dev/articles/cls

## Load Strategies

A loading strategy specifies when media or the poster image should begin loading. Loading media too
early can effectively slow down your entire application, so choose wisely.

The following media loading strategies are available:

- `eager`: Load media immediately - use when media needs to be interactive as soon as possible.
- `idle`: Load media once the page has loaded and the `requestIdleCallback` is fired - use when
  media is lower priority and doesn't need to be interactive immediately.
- `visible`: Load media once it has entered the visual viewport - use when media is below the fold
  and you prefer delaying loading until it's required.
- `play`: Load the provider and media on play - use when you want to delay loading until interaction.
- `custom`: Load media when the `startLoading()`/`startLoadingPoster()` method is called or
  the `media-start-loading`/`media-start-loading-poster` event is dispatched - use when you need
  fine control of when media should begin loading.

::code[./load-strategy]

:::info
The poster load strategy specifies when the poster should begin loading. Poster loading is separate
from media loading so you can display an image before media is ready for playback. This
generally works well in combination with `load="play"` to create thumbnails.
:::

### Custom Strategy

A custom load strategy lets you control when media or the poster image should begin loading:

::code[./load-custom-strategy]

## View Type

The view type suggests what type of media layout will be displayed. It can be either `audio` or
`video`. This is mostly to inform layouts, whether your own or the defaults, how to appropriately
display the controls and general UI. By default, the view type is inferred from the provider and
media type. You can specify the desired type like so:

::code[./view-type]

## Stream Type

The stream type refers to the mode in which content is delivered through the video player. The
player will use the type to determine how to manage state/internals such as duration updates,
seeking, and how to appropriately present UI components and layouts. The stream type can be one of
the following values:

- `on-demand`: Video on Demand (VOD) content is pre-recorded and can be accessed and played at any
  time. VOD streams allow viewers to control playback, pause, rewind, and fast forward.
- `live`: Live streaming delivers real-time content as it happens. Viewers join the stream and
  watch the content as it's being broadcast, with limited control over playback.
- `live:dvr`: Live DVR (Live Digital Video Recording) combines the features of both live and VOD.
  Viewers can join a live stream and simultaneously pause, rewind, and fast forward, offering more
  flexibility in watching live events.
- `ll-live`: A live streaming mode optimized for reduced latency, providing a near-real-time
  viewing experience with minimal delay between the live event and the viewer.
- `ll-live:dvr`: Similar to low-latency live, this mode enables viewers to experience live content
  with minimal delay while enjoying the benefits of DVR features (same as `live:dvr`).

If the value is not set, it will be inferred by the player which can be less accurate (e.g., at
identifying DVR support). When possible, prefer specifying it like so:

::code[./stream-type]

## Duration

By default, the duration is inferred from the provider and media. It's always best to provide
the duration when known to avoid any inaccuracies such as rounding errors, and to ensure UI is
set to the correct state without waiting on metadata to load. You can specify the exact duration like so:

::code[./duration]

## Clipping

Clipping allows shortening the media by specifying the time at which playback should start
and end.

::code[./clipping]

- You can set a clip start time or just an end time, both are not required.
- The media duration and chapter durations will be updated to match the clipped length.
- Any media resources such as text tracks and thumbnails should use the full duration.
- Seeking to a new time is based on the clipped duration. For example, if a 1 minute video is clipped
  to 30 seconds, seeking to 30s will be the end of the video.
- [Media URI Fragments][media-frags] are set internally to efficiently load audio and video files
  between the clipped start and end times (e.g., `/video.mp4#t=30,60`).

[media-frags]: https://www.w3.org/TR/media-frags

## Media Session

The [Media Session API][mdn-media-session] is automatically set using the provided `title`,
`artist`, and `artwork` (`poster` is used as fallback) player properties.

[mdn-media-session]: https://developer.mozilla.org/en-US/docs/Web/API/Media_Session_API

## Storage

Storage enables saving player and media settings so that the user can resume where they left off.
This includes saving and initializing on load settings such as language, volume,
muted, captions visibility, and playback time.

### Local Storage

[Local Storage][local-storage] enables saving data locally on the user's browser. This is
a simple and fast option for remembering player settings, but it _won't_ persist across domains,
devices, or browsers.

Provide a storage key prefix for turning local storage on like so:

::code[./local-storage]

**Extending Local Storage**

Optionally, you can extend and customize local storage behaviour like so:

::code[./local-storage-extend]

[local-storage]: https://developer.mozilla.org/en-US/docs/Web/API/Storage

### Remote Storage

Remote Storage enables asynchronously saving and loading data from anywhere. This is great
as settings willl persist across user sessions even if the domain, device, or browser changes.
Generally, you will save player/media settings to a remote database based on the currently authenticated
user.

Implement the `MediaStorage` interface and provide it to the player like so:

::code[./remote-storage]{copy=true}

::code[./provide-remote-storage]

## Sources

The player can accept one or more media sources which can be a `string` URL of the media resource
to load, or any of the following objects: `MediaStream`, `MediaSource`, `Blob`, or `File`.

**Single Source**

::code[./single-source]

**Multiple Source Types**

The list of [supported media formats](#supported-codecs) varies from one browser to the other. You should
either provide your source in a single format that all relevant browsers support, or provide multiple
sources in enough different formats that all the browsers you need to support are covered.

::code[./multiple-sources]

### Source Objects

The player accepts both audio and video source objects. This includes [MediaStream][media-stream],
[MediaSource][media-source], [Blob][blob], and [File][file].

::code[./source-object]

[media-stream]: https://developer.mozilla.org/en-US/docs/Web/API/MediaStream
[media-source]: https://developer.mozilla.org/en-US/docs/Web/API/MediaSource
[blob]: https://developer.mozilla.org/en-US/docs/Web/API/Blob
[file]: https://developer.mozilla.org/en-US/docs/Web/API/File

### Changing Source

The player supports changing the source dynamically. Simply update the `src` property when you
want to load new media. You can also set it to an empty string `""` to unload media.

::code[./source-management]

### Source Types

The player [source selection][source-selection] process relies on file extensions, object types,
and type hints to determine which provider to load and how to play a given source. The following
is a table of supported media file extensions and types for each provider:

| Media     | Extensions                                                               | Types                                                                                                                                     |
| --------- | ------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------- |
| **Audio** | m4a, m4b, mp4a, mpga, mp2, mp2a, mp3, m2a, m3a, wav, weba, aac, oga, spx | audio/mpeg, audio/ogg, audio/3gp, audio/mp4, audio/webm, audio/flac, audio/object                                                         |
| **Video** | mp4, ogg, ogv, webm, mov, m4v                                            | video/mp4, video/webm, video/3gp, video/ogg, video/avi, video/mpeg                                                                        |
| **HLS**   | m3u8                                                                     | application/vnd.apple.mpegurl, audio/mpegurl, audio/x-mpegurl, application/x-mpegurl, video/x-mpegurl, video/mpegurl, application/mpegurl |
| **DASH**  | mpd                                                                      | application/dash+xml                                                                                                                      |

:::yes
The following are valid as they have a file extension (e.g, `video.mp4`) or type
hint (e.g., `video/mp4`):
:::

- `src="https://example.com/video.mp4"`
- `src="https://example.com/hls.m3u8"`
- `src="https://example.com/dash.mpd"`
- `src = { src: "https://example.com/video", type: "video/mp4"  }`
- `src = { src: "https://example.com/hls", type: "application/x-mpegurl"  }`
- `src = { src: "https://example.com/dash", type: "application/dash+xml"  }`

:::no
The following are invalid as they are missing a file extension and type hint:
:::

- `src="https://example.com/video"`
- `src="https://example.com/hls"`
- `src="https://example.com/dash"`

[source-selection]: /docs/player/getting-started/architecture#source-selection

### Source Sizes

You can provide video qualities/resolutions using multiple video files with different
sizes (e.g, 1080p, 720p, 480p) like so:

::code[./source-sizes]

:::note
We strongly recommend using adaptive streaming protocols such as HLS over providing multiple
static media files, see the [Video Qualities](#video-qualities) section for more information.
:::

### Supported Codecs

Vidstack Player relies on the native browser runtime to handle media playback, hence it's
important you review what containers and codecs are supported by them. This also applies to
libraries like [`hls.js`][hlsjs] and [`dash.js`][dashjs] which we use for HLS/DASH playback in
browsers that don't support it natively.

While there are a vast number of media container formats, the ones listed below are the ones
you are most likely to encounter. Some support only audio while others support both audio and
video. The most commonly used containers for media on the web are probably MPEG-4 (MP4), Web Media
File (WEBM), and MPEG Audio Layer III (MP3).

**It's important that both the media container and codecs are supported by the native runtime.**
Please review the following links for what's supported and where:

- [Media Containers][media-containers]
- [Audio Codecs][audio-codecs]
- [Video Codecs][video-codecs]

[hlsjs]: https://github.com/video-dev/hls.js
[dashjs]: https://github.com/Dash-Industry-Forum/dash.js
[media-containers]: https://developer.mozilla.org/en-US/docs/Web/Media/Formats/Containers
[audio-codecs]: https://developer.mozilla.org/en-US/docs/Web/Media/Formats/Audio_codecs
[video-codecs]: https://developer.mozilla.org/en-US/docs/Web/Media/Formats/Video_codecs

## Providers

Providers are auto-selected during the [source selection][source-selection] process and
dynamically loaded via a provider loader (e.g., `VideoProviderLoader`). The following providers
are supported at this time:

- [Audio][audio-provider]
- [Video][video-provider]
- [HLS][hls-provider]
- [DASH][dash-provider]
- [YouTube][youtube-provider]
- [Vimeo][vimeo-provider]
- [Remotion][remotion-provider]
- [Google Cast][gcast-provider]

:::info
See [source types](#source-types) for how to ensure the correct media provider is loaded.
:::

[audio-provider]: /docs/player/api/providers/audio
[video-provider]: /docs/player/api/providers/video
[hls-provider]: /docs/player/api/providers/hls
[dash-provider]: /docs/player/api/providers/dash
[youtube-provider]: /docs/player/api/providers/youtube
[vimeo-provider]: /docs/player/api/providers/vimeo
[remotion-provider]: /docs/player/api/providers/remotion
[gcast-provider]: /docs/player/api/providers/google-cast

### Provider Events

The following events will fire as providers change or setup:

::code[./provider-events]

### Provider Types

The following utilities can be useful for narrowing the type of a media provider:

::code[./provider-types]

## Audio Tracks

Audio tracks are loaded from your HLS playlist. You can not manually add audio tracks to the
player at this time. See the [Audio Tracks API][audio-tracks-api] guide for how to interact
with audio track programmatically.

[audio-tracks-api]: /docs/player/api/audio-tracks

## Text Tracks

Text tracks allow you to provide text-based information or content associated with video
or audio. These text tracks can be used to enhance the accessibility and user experience of
media content in various ways. You can provide multiple text tracks dynamically like so:

::code[./text-tracks]

:::info
See the [Text Tracks API][text-tracks-api] guide for how to interact with text tracks programmatically.
:::

[text-tracks-api]: /docs/player/api/text-tracks

### Text Track Default

When `default` is set on a text track it will set the mode of that track to showing immediately. In
other words, this track is immediately active. Only one default is allowed
per [track kind](#text-track-kinds).

::code[./text-track-default]

### Text Track Formats

The [vidstack/media-captions][media-captions] library handles loading, parsing, and rendering
captions inside of the player. The following caption formats are supported:

- [VTT][captions-vtt]
- [SRT][captions-srt]
- [SSA/ASS][captions-ssa]
- [JSON](#json-tracks)

See the links provided for more information and any limitations. Do note, all caption formats
are mapped to VTT which is extended to support custom styles. In addition, browsers or
providers may also support loading additional text tracks. For example, Safari and the HLS provider
will load captions embedded in HLS playlists.

You can specify the desired text track format like so:

::code[./text-track-type]

[media-captions]: https://github.com/vidstack/media-captions
[captions-vtt]: https://github.com/vidstack/media-captions#vtt
[captions-srt]: https://github.com/vidstack/media-captions#srt
[captions-ssa]: https://github.com/vidstack/media-captions#ssaass

### Text Track Kinds

The following text track kinds are supported:

- `subtitles`: Provides a written version of the audio for non-native speakers.
- `captions`: Includes dialog and descriptions of important audio elements, like music
  or sound effects.
- `chapters`: Contains information (e.g, title and start times) about the different
  chapters or sections of the media file.
- `descriptions`: Provides information about the visual content to assist individuals who are
  blind or visually impaired.
- `metadata`: Additional information or descriptive data within a media file. This metadata can
  be used for various purposes, like providing descriptions, comments, or annotations related to the
  media content. It is not displayed as subtitles or captions but serves as background information
  that can be used for various purposes, including search engine optimization, accessibility enhancements,
  or supplementary details for the audience.

::code[./text-track-kind]

### JSON Tracks

JSON content can be provided directly to text tracks or loaded from a remote location like so:

::code[./text-track-json]

::code[./text-track-json-html]

Example JSON text tracks:

::code[./json-tracks]

::code[./provide-json-tracks]

Example JSON cues:

::code[./json-cues]{title=cues.json}

Example JSON regions and cues:

::code[./json-regions]{title=regions.json}

[vtt-region]: https://github.com/vidstack/media-captions/blob/main/src/vtt/vtt-region.ts
[vtt-cue]: https://github.com/vidstack/media-captions/blob/main/src/vtt/vtt-cue.ts

### LibASS

We provide a direct integration for a [WASM port of libass][jassub] if you'd like to use advanced
ASS features that are [not supported][captions-ssa].

1. `npm i jassub`

2. Copy the `node_modules/jassub/dist` directory to your public directory (e.g, `public/jassub`)

3. Add the `LibASSTextRenderer` to the player like so:

::code[./libass]{copy=true}

:::info
See the [JASSUB options][jassub-options] for how to further configure the LibASS renderer.
:::

[jassub]: https://github.com/ThaUnknown/jassub
[jassub-options]: https://github.com/ThaUnknown/jassub#options

## Thumbnails

Thumbnails are small, static images or frames extracted from the video or audio content. These
images serve as a visual preview or representation of the media content, allowing users to quickly
identify and navigate to specific points within the video or audio. Thumbnails are often displayed
in the time slider or chapters menu; enabling users to visually browse and select the part of
the content they want to play.

### Usage

Thumbnails can be loaded using the [Thumbnail][thumbnail] component or [`useThumbnails`][use-thumbnails] hook.
They're also supported out the box by the [Default Layout][default-layout-thumbnails] and
[Plyr Layout][plyr-layout-thumbnails].

::code[./provide-thumbnail-vtt]

### VTT

Thumbnails are generally provided in the [Web Video Text Tracks][webvtt] (WebVTT) format. The WebVTT file
specifies the time ranges of when to display images, with the respective image URL and coordinates
(only required if using a sprite). You can refer to our [thumbnails example][thumbnails-example] to
get a better idea of how this file looks.

**Sprite**

Sprites are [large storyboard images][storyboard] that contain multiple small tiled thumbnails.
They're preferred over loading multiple images because:

- Sprites reduce total file size due to compression.
- Avoid loading delays for each thumbnail.
- Reduce the number of server requests.

The WebVTT file must append the coordinates of each thumbnail like so:

::code[./thumbnail-sprite-vtt]

**Multiple Images**

Sprites should generally be preferred but in the case you only have multiple individual
thumbnail images, they can be specified like so:

::code[./thumbnail-multiple-images]

### JSON

Thumbnails can be loaded as a JSON file. Ensure the `Content-Type` header is
set to `application/json` on the response. The returned JSON can be VTT cues, an array of images, or
a storyboard.

::code[./provide-thumbnail-json]

[Mux storyboards][mux-storyboard] are supported out of the box:

::code[./thumbnails-mux]

Example JSON VTT:

::code[./thumbnail-vtt-json]{title="vtt.json"}

Example JSON images:

::code[./thumbnail-images-json]{title="images.json"}

Example JSON storyboard:

::code[./thumbnail-storyboard-json]{title="storyboard.json"}

### Object

Example object with multiple images:

::code[./thumbnail-image-object]

Example storyboard object:

::code[./thumbnail-storyboard-object]

Provide objects directly like so:

::code[./provide-thumbnail-object]

[webvtt]: https://developer.mozilla.org/en-US/docs/Web/API/WebVTT_API
[thumbnail]: /docs/player/components/display/thumbnail
[storyboard]: https://files.vidstack.io/sprite-fight/storyboard.jpg
[mux-storyboard]: https://docs.mux.com/guides/create-timeline-hover-previews#json
[thumbnails-example]: https://files.vidstack.io/sprite-fight/thumbnails.vtt
[use-thumbnails]: /docs/player/api/hooks/use-thumbnails
[default-layout-thumbnails]: /docs/player/components/layouts/default-layout#thumbnails
[plyr-layout-thumbnails]: /docs/player/components/layouts/plyr-layout#thumbnails

## Video Qualities

Adaptive streaming protocols like [HLS][hls-wiki] and [DASH][dash-wiki] not only enable streaming
media in chunks, but also have the ability to adapt playback quality based on the device size,
network conditions, and other information. Adaptive qualities is important for speeding up
initial delivery and to avoid loading excessive amounts of data which cause painful buffering delays.

Video streaming platforms such as [Cloudflare Stream][cf-stream] and [Mux][mux] will take an input
video file (e.g., awesome-video.mp4) and create multiple renditions out of the box for you,
with multiple resolutions (width/height) and bit rates:

<img
  src={hlsManifestImage.src}
  alt="HLS manifest with multiple child resolution manifests."
  decoding="async"
  loading="lazy"
  style="aspect-ratio: 2 / 1"
/>

By default, the best quality is automatically selected by the streaming engine such as [hls.js][hlsjs] or
[dash.js][dashjs]. You'll usually see this as an "Auto" option in the player quality menu. It can
also be manually set if the engine is not making optimal decisions, as they're generally more
conservative to avoid excessive bandwidth usage.

Once you have your HLS or DASH playlist by either creating it yourself using [FFMPEG][ffmpeg] or
using a streaming provider, you can pass it to the player like so:

::code[./play-hls]

:::info
See the [Video Qualities API][video-quality-api] guide for how to interact with renditions
programmatically.
:::

[ffmpeg]: https://www.ffmpeg.org
[video-quality-api]: /docs/player/api/video-quality
[hls-wiki]: https://en.wikipedia.org/wiki/HTTP_Live_Streaming
[dash-wiki]: https://en.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP
[cf-stream]: https://www.cloudflare.com/products/cloudflare-stream
[mux]: https://www.mux.com
